{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "%matplotlib inline\n",
        "\n",
        "df_train = pd.read_csv('train_toxic.csv')\n",
        "print(df_train.head(10))\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "df_test = pd.read_csv(\"test_toxic.csv\")\n",
        "print(df_test.head(10))\n",
        "\n",
        "\n",
        "df_mixed_train = pd.read_csv(\"train_toxic_mixed.csv\")\n",
        "print(df_test.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW-cTWYxGiaq",
        "outputId": "3903c07c-56dd-4345-80bc-767a0704ce78"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text is_toxic\n",
            "0  Yine de Pestagyang kadar adım atarak Gestapo t...      yes\n",
            "1  Kendimi aptal hissettirdi ya günlerce delirdim...      yes\n",
            "2  Hakkında hayırlısı olsun Bul birini kuttulak s...      yes\n",
            "3  Makaleyi yeniden adlandır Bu makalenin adı Alb...       no\n",
            "4  Atların dişleri yaşlandıkça uzar ve atın gerçe...       no\n",
            "5      delii ayyaş işte ayık olsa normal dusunecekte      yes\n",
            "6                     Çilesiz bir günüm olmadı gitti       no\n",
            "7      ne kıvırcık ne kısa ezelin kör anası mısın aq      yes\n",
            "8             Bunların topu yakacan bunlar tam kahpe      yes\n",
            "9  lan dur amk rumu zaten ortalık karışık sen zat...      yes\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                text is_toxic\n",
            "0  Lan siktirin gidin AMK pozitif sik kafaları Ül...      yes\n",
            "1  Kabul Dream Chaser programı ile ilgili olmayan...       no\n",
            "2  Thanx Teşekkürler Bay horoz Bana son bir şans ...       no\n",
            "3                Zeka yaşı falan da orası ayrı sjsjd      yes\n",
            "4  LGagnon içeren kişisel bir saldırıdan devam ed...       no\n",
            "5  Bu doğru evlat incinmiş gurur iddiaları altınd...       no\n",
            "6  Olası olarak serbest resim FSILogo PNG Yükledi...       no\n",
            "7         Herşeyden biraz var Hiç bir şeyden tam yok       no\n",
            "8  terimin kökeninin yanlış yazımı Bu makalede Ka...       no\n",
            "9  Estağfurullah abi Asıl ben bu hizmetteki güzel...       no\n",
            "                                                text is_toxic\n",
            "0  Lan siktirin gidin AMK pozitif sik kafaları Ül...      yes\n",
            "1  Kabul Dream Chaser programı ile ilgili olmayan...       no\n",
            "2  Thanx Teşekkürler Bay horoz Bana son bir şans ...       no\n",
            "3                Zeka yaşı falan da orası ayrı sjsjd      yes\n",
            "4  LGagnon içeren kişisel bir saldırıdan devam ed...       no\n",
            "5  Bu doğru evlat incinmiş gurur iddiaları altınd...       no\n",
            "6  Olası olarak serbest resim FSILogo PNG Yükledi...       no\n",
            "7         Herşeyden biraz var Hiç bir şeyden tam yok       no\n",
            "8  terimin kökeninin yanlış yazımı Bu makalede Ka...       no\n",
            "9  Estağfurullah abi Asıl ben bu hizmetteki güzel...       no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = df_train.text\n",
        "y_train = df_train.is_toxic\n",
        "\n",
        "x_test= df_test.text\n",
        "y_test = df_test.is_toxic\n",
        "\n",
        "x_mixed_train = df_mixed_train.text\n",
        "y_mixed_train = df_mixed_train.is_toxic\n",
        "\n",
        "x_mixed_test= df_test.text\n",
        "y_test = df_test.is_toxic\n"
      ],
      "metadata": {
        "id": "nDJbeyQRG1lE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF0lB174GcEi",
        "outputId": "85344fbe-2729-46ea-bb59-0cfbfc435553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------Naive Bayes, base ------\n",
            "accuracy 0.875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         yes       0.86      0.89      0.88       995\n",
            "          no       0.89      0.86      0.87      1005\n",
            "\n",
            "    accuracy                           0.88      2000\n",
            "   macro avg       0.88      0.88      0.87      2000\n",
            "weighted avg       0.88      0.88      0.87      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(x_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(x_test)\n",
        "\n",
        "print(\"------Naive Bayes, base ------\")\n",
        "my_labels = [\"yes\", \"no\"]\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "NB_base_report = classification_report(y_test, y_pred,target_names=my_labels)\n",
        "print(NB_base_report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_mixed_default_train = pd.read_csv(\"train_toxic_default_mixed.csv\")\n",
        "\n",
        "\n",
        "x_mixed_default_train = df_mixed_default_train.text\n",
        "y_mixed_default_train = df_mixed_default_train.is_toxic\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(x_mixed_default_train, y_mixed_default_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(x_test)\n",
        "\n",
        "print(\"------Naive Bayes, data augmented with default gpt2------\")\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "NB_default_augmented_report = classification_report(y_test, y_pred,target_names=my_labels)\n",
        "print(NB_default_augmented_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAJZ7a8vk88E",
        "outputId": "761d600c-ff88-4633-b225-f09e0d1f11ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------Naive Bayes, data augmented with default gpt2------\n",
            "accuracy 0.805\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         yes       0.72      0.99      0.84       995\n",
            "          no       0.99      0.62      0.76      1005\n",
            "\n",
            "    accuracy                           0.81      2000\n",
            "   macro avg       0.86      0.81      0.80      2000\n",
            "weighted avg       0.86      0.81      0.80      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(x_mixed_train, y_mixed_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(x_mixed_test)\n",
        "\n",
        "print(\"------Naive Bayes, data augmented with our model------\")\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "NB_augmented_report = classification_report(y_test, y_pred,target_names=my_labels)\n",
        "print(NB_augmented_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEEDPFwPLepx",
        "outputId": "b9c8563c-7450-440f-ea95-6c58e121fd39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------Naive Bayes, data augmented with our model------\n",
            "accuracy 0.825\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         yes       0.74      0.99      0.85       995\n",
            "          no       0.99      0.66      0.79      1005\n",
            "\n",
            "    accuracy                           0.82      2000\n",
            "   macro avg       0.87      0.83      0.82      2000\n",
            "weighted avg       0.87      0.82      0.82      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"base\\n\")\n",
        "print(NB_base_report)\n",
        "print(\"------------------------------------------\")\n",
        "print(\"data augmented with baseline gpt2\\n\")\n",
        "print(NB_default_augmented_report)\n",
        "print(\"------------------------------------------\")\n",
        "\n",
        "print(\"data augmented with our model\\n\")\n",
        "print(NB_augmented_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-IfzobNQ15X",
        "outputId": "1acef0e1-b45f-4b6b-fa6b-40462947a509"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         yes       0.86      0.89      0.88       995\n",
            "          no       0.89      0.86      0.87      1005\n",
            "\n",
            "    accuracy                           0.88      2000\n",
            "   macro avg       0.88      0.88      0.87      2000\n",
            "weighted avg       0.88      0.88      0.87      2000\n",
            "\n",
            "------------------------------------------\n",
            "data augmented with baseline gpt2\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         yes       0.72      0.99      0.84       995\n",
            "          no       0.99      0.62      0.76      1005\n",
            "\n",
            "    accuracy                           0.81      2000\n",
            "   macro avg       0.86      0.81      0.80      2000\n",
            "weighted avg       0.86      0.81      0.80      2000\n",
            "\n",
            "------------------------------------------\n",
            "data augmented with our model\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         yes       0.74      0.99      0.85       995\n",
            "          no       0.99      0.66      0.79      1005\n",
            "\n",
            "    accuracy                           0.82      2000\n",
            "   macro avg       0.87      0.83      0.82      2000\n",
            "weighted avg       0.87      0.82      0.82      2000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}