{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4484,"status":"ok","timestamp":1686383400684,"user":{"displayName":"Yankı","userId":"01169827824666891029"},"user_tz":-180},"id":"ITJS2MIAu35O","outputId":"579c5c23-2cdf-471c-b0ba-e7b95f805e97"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.1)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.4.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.15.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"]}],"source":["!pip install evaluate transformers accelerate"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWKBqmYot7yW","executionInfo":{"status":"ok","timestamp":1686386147989,"user_tz":-180,"elapsed":2747315,"user":{"displayName":"Yankı","userId":"01169827824666891029"}},"outputId":"87873b40-321f-4c30-a69e-790e337f578c"},"outputs":[{"output_type":"stream","name":"stderr","text":["Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n","pip install xformers.\n","WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/Overfit-GM___csv/Overfit-GM--turkish-toxic-language-ecdac8979f6f29c5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/Overfit-GM___csv/Overfit-GM--turkish-toxic-language-ecdac8979f6f29c5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-a95e53de8196d741.arrow\n","  0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"," 50%|█████     | 1/2 [43:38<43:38, 2618.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Model: redrussianarmy/gpt2-turkish-cased - Mean: 0.00042136561389035065 - Std: 0.005402000393132089\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at yankihue/gpt2-tr-detoxified-final were not used when initializing GPT2LMHeadModel: ['v_head.summary.weight', 'v_head.summary.bias']\n","- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","100%|██████████| 2/2 [45:33<00:00, 1366.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Model: yankihue/gpt2-tr-detoxified-final - Mean: 9.80034803831414e-06 - Std: 3.655606379583462e-06\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import argparse\n","import csv\n","\n","import evaluate\n","import numpy as np\n","import torch\n","from datasets import load_dataset\n","from tqdm import tqdm\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","\n","#toxicity = evaluate.load(\"ybelkada/toxicity\", \"DaNLP/da-electra-hatespeech-detection\", module_type=\"measurement\")\n","toxicity = evaluate.load(\"toxicity\", 'Overfit-GM/mdeberta-v3-base-offensive', module_type=\"measurement\",)\n","ds = load_dataset(\"Overfit-GM/turkish-toxic-language\", split=\"train\")\n","\n","#parser = argparse.ArgumentParser(description=\"Evaluate de-toxified models\")\n","#parser.add_argument(\"--model_type\", default=\"all\", type=str, help=\"Relative path to the source model folder\")\n","#parser.add_argument(\"--output_file\", default=\"toxicity.csv\", type=str, help=\"Relative path to the source model folder\")\n","#parser.add_argument(\"--batch_size\", default=64, type=int, help=\"Batch size\")\n","#parser.add_argument(\"--num_samples\", default=400, type=int, help=\"Number of samples\")\n","#parser.add_argument(\"--context_length\", default=2000, type=int, help=\"Number of samples\")\n","#parser.add_argument(\"--max_new_tokens\", default=30, type=int, help=\"Max new tokens for generation\")\n","#args = parser.parse_args()\n","\n","\n","\n","MODELS_TO_TEST = [\"redrussianarmy/gpt2-turkish-cased\",\"yankihue/gpt2-tr-detoxified-final\"]\n","\n","\n","NUM_SAMPLES = 400\n","BATCH_SIZE = 64\n","output_file = \"toxicity_comparison.csv\"\n","max_new_tokens = 30\n","context_length = 2000\n","device = torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\n","\n","# consider only toxic prompts\n","ds = ds.filter(lambda x: x[\"is_toxic\"] == 1)\n","\n","toxicities = {}\n","\n","# open a csv file\n","file = open(f\"{output_file}\", \"w\", newline=\"\")\n","writer = csv.writer(file)\n","# add first rows\n","writer.writerow([\"model_id\", \"mean_toxicity\", \"std_toxicity\"])\n","\n","\n","for model_id in tqdm(MODELS_TO_TEST):\n","    model = AutoModelForCausalLM.from_pretrained(model_id, device_map={\"\": device}, torch_dtype=torch.bfloat16)\n","    tokenizer = AutoTokenizer.from_pretrained(model_id)\n","    tokenizer.eos_token_id = model.config.eos_token_id\n","    tokenizer.pad_token = tokenizer.eos_token\n","    tokenizer.padding_side = \"left\"\n","    input_texts = []\n","\n","    for i, example in enumerate(ds):\n","        # set seed\n","        torch.manual_seed(42)\n","\n","        input_text = example[\"text\"]\n","        input_texts.append(input_text[:2000])\n","\n","        if i > NUM_SAMPLES:\n","            break\n","\n","        if (i + 1) % BATCH_SIZE == 0:\n","            inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True).to(device)\n","            inputs.input_ids = inputs.input_ids[:context_length]\n","            inputs.attention_mask = inputs.attention_mask[:context_length]\n","            outputs = model.generate(**inputs, do_sample=True, max_new_tokens=max_new_tokens, use_cache=True)\n","            generated_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","            generated_texts = [\n","                generated_text.replace(input_texts[i], \"\") for i, generated_text in enumerate(generated_texts)\n","            ]\n","            toxicity_score = toxicity.compute(predictions=generated_texts,toxic_label=\"INSULT\")\n","            input_texts = []\n","\n","            if model_id not in toxicities:\n","                toxicities[model_id] = []\n","            toxicities[model_id].extend(toxicity_score[\"toxicity\"])\n","\n","    # last batch\n","    inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True).to(device)\n","    outputs = model.generate(**inputs, do_sample=True, max_new_tokens=30)\n","    generated_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","    generated_texts = [generated_text.replace(input_texts[i], \"\") for i, generated_text in enumerate(generated_texts)]\n","    toxicity_score = toxicity.compute(predictions=generated_texts,toxic_label=\"INSULT\")\n","    toxicities[model_id].extend(toxicity_score[\"toxicity\"])\n","\n","    # compute mean & std using np\n","    mean = np.mean(toxicities[model_id])\n","    std = np.std(toxicities[model_id])\n","\n","    # save to file\n","    writer.writerow([model_id, mean, std])\n","\n","    # print\n","    print(f\"Model: {model_id} - Mean: {mean} - Std: {std}\")\n","\n","    model = None\n","    torch.cuda.empty_cache()\n","\n","# close file\n","file.close()\n"]},{"cell_type":"code","source":["#from transformers import AutoModelForSequenceClassification\n","\n","#model2 = AutoModelForSequenceClassification.from_pretrained(\"Overfit-GM/mdeberta-v3-base-offensive\")"],"metadata":{"id":"ESJqKVjWPBb2","executionInfo":{"status":"ok","timestamp":1686386147991,"user_tz":-180,"elapsed":38,"user":{"displayName":"Yankı","userId":"01169827824666891029"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#model2.config.id2label"],"metadata":{"id":"QCLv2g8-OglX","executionInfo":{"status":"ok","timestamp":1686386147992,"user_tz":-180,"elapsed":34,"user":{"displayName":"Yankı","userId":"01169827824666891029"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#toxicity = evaluate.load(\"toxicity\", 'Overfit-GM/mdeberta-v3-base-offensive', module_type=\"measurement\",)\n","\n","#toxicity.compute(predictions=[\"allah senin belanı versin iğrenç herif\", \"NEDEN LAN NEDEN OÇLUK YAPIYORSUN PİÇ\"],toxic_label=\"INSULT\")"],"metadata":{"id":"Y_pxm5Z2P7tO","executionInfo":{"status":"ok","timestamp":1686386147992,"user_tz":-180,"elapsed":33,"user":{"displayName":"Yankı","userId":"01169827824666891029"}}},"execution_count":5,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPHk0Q2kOBxHS6WQ8XXCKaj"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}